{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from kronvec import kron_diag as get_diag_paired\n",
    "# from Utilityfunctions import reachable_states\n",
    "import itertools\n",
    "from scipy.linalg.blas import dcopy, dscal, daxpy\n",
    "\n",
    "n = 8\n",
    "np.random.seed(2)\n",
    "log_theta = 2 * np.random.random(size=(n + 1, n + 1)) - 1\n",
    "tau1, tau2 = np.random.random(2) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diag_unpaired(log_theta, state: np.array) -> np.array:\n",
    "    \"\"\"This returns the diagonal of the restricted rate matrix of the metMHN's Markov chain.\n",
    "\n",
    "    Args:\n",
    "        state (np.array): Binary unpaired state vector, dtype must be int32. This is the vector according\n",
    "        to which state space restriction will be performed. Shape (n,) with n the number of events including\n",
    "        seeding.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Diagonal of the restricted rate matrix. Shape (2^k,) with k the number of 1s in state.\n",
    "    \"\"\"\n",
    "    k = state.sum()\n",
    "    nx = 1 << k\n",
    "    n = log_theta.shape[0]\n",
    "    diag = np.zeros(nx)\n",
    "    subdiag = np.zeros(nx)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        current_length = 1\n",
    "        subdiag[0] = 1\n",
    "        # compute the ith subdiagonal of Q\n",
    "        for j in range(n):\n",
    "            if state[j]:\n",
    "                exp_theta = np.exp(log_theta[i, j])\n",
    "                if i == j:\n",
    "                    exp_theta *= -1\n",
    "                    dscal(n=current_length, a=exp_theta, x=subdiag, incx=1)\n",
    "                    dscal(n=current_length, a=0,\n",
    "                            x=subdiag[current_length:], incx=1)\n",
    "                else:\n",
    "                    dcopy(n=current_length, x=subdiag, incx=1,\n",
    "                            y=subdiag[current_length:], incy=1)\n",
    "                    dscal(n=current_length, a=exp_theta,\n",
    "                            x=subdiag[current_length:], incx=1)\n",
    "\n",
    "                current_length *= 2\n",
    "\n",
    "            elif i == j:\n",
    "                exp_theta = - np.exp(log_theta[i, j])\n",
    "                dscal(n=current_length, a=exp_theta, x=subdiag, incx=1)\n",
    "\n",
    "        # add the subdiagonal to dg\n",
    "        daxpy(n=nx, a=1, x=subdiag, incx=1, y=diag, incy=1)\n",
    "    return diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bits_fixed_n:\n",
    "    \"\"\"\n",
    "    Iterator over integers whose binary representation has a fixed number of 1s, in lexicographical order.\n",
    "    From https://graphics.stanford.edu/~seander/bithacks.html#NextBitPermutation\n",
    "\n",
    "    :param n: How many 1s there should be\n",
    "    :param k: How many bits the integer should have\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, k):\n",
    "        self.v = int(\"1\"*n, 2)\n",
    "        self.stop_no = int(\"1\"*n + \"0\"*(k-n), 2)\n",
    "        self.stop = False\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.stop:\n",
    "            raise StopIteration\n",
    "        if self.v == self.stop_no:\n",
    "            self.stop = True\n",
    "        t = (self.v | (self.v - 1)) + 1\n",
    "        w = t | ((((t & -t)) // (self.v & (-self.v)) >> 1) - 1)\n",
    "        self.v, w = w, self.v\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reachable_states(n: int) -> np.array:\n",
    "    \"\"\"This function returns the indices, w.r.t. to a lexicographical ordering, of the states\n",
    "    of an MHN with n events, that can actually be reached.\n",
    "\n",
    "    Args:\n",
    "        n (int): Number of events\n",
    "\n",
    "    Returns:\n",
    "        np.array: dtype bool, True if the state is reachable, False if not.\n",
    "    \"\"\"\n",
    "    reachable = np.zeros(2**(2*n + 1))\n",
    "\n",
    "    for i in itertools.chain.from_iterable(itertools.combinations(list(range(n)), r) for r in range((n+1))):\n",
    "        reachable[sum((2**(2*j))*3 for j in i)] = 1\n",
    "\n",
    "    reachable[2**(2*n):] = 1\n",
    "    return reachable.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssr_to_fss(state: np.array) -> np.array:\n",
    "    \"\"\"This gives the indices of the rate matrix that are appearing in the\n",
    "    state space restricted rate matrix.\n",
    "\n",
    "    Args:\n",
    "        state (np.array): Binary state vector, representing the current sample's events.\n",
    "    Returns:\n",
    "        np.array: Indices of the rate matrix.\n",
    "    \"\"\"\n",
    "    res = np.ones(1)\n",
    "    for s in state:\n",
    "        res = np.kron(np.array([1, s]), res)\n",
    "    return res.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_sort(x: dict, y: dict) -> tuple[dict, dict]:\n",
    "    argmax_x = max(x, key=x.get)\n",
    "    argmax_y = max(y, key=y.get)\n",
    "    keys = [k for k in x if x[k] >= x[argmax_y] and y[k] >= y[argmax_x]]\n",
    "    return (\n",
    "        {k: x[k] for k in keys},\n",
    "        {k: y[k] for k in keys}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.187908060005101e-08\n",
      "4.7796274578388204e-08\n",
      "1.196753551784392e-07\n"
     ]
    }
   ],
   "source": [
    "def likelihood(order_1, order_2, log_theta, tau1, tau2):\n",
    "    \"\"\" Compute the likelihood of two orders of events happening before the first\n",
    "    and the second observation \n",
    "\n",
    "    Args:\n",
    "        order_1 (np.array): Order of events (2i and 2i+1 encode the ith events happening in PT and Met respectively)\n",
    "        that have happened when the first observation has been made. Note that these do not correspond to the actual PT\n",
    "        observation, as it is possible that events have happened in the metastasis that are not visible in the PT \n",
    "        observation.\n",
    "        order_2 (_type_): Order of events (2i and 2i+1 encode the ith events happening in PT and Met respectively)\n",
    "        that have happened when the second observation has been made. Note that these do not correspond to the actual Met\n",
    "        observation, as it is possible that events have happened in the primary tumor that are not visible in the Met \n",
    "        observation.\n",
    "        log_theta (_type_): Logarithmic theta values\n",
    "        tau1 (_type_): rate of first observation\n",
    "        tau2 (_type_): rate of second observation\n",
    "\n",
    "    Returns:\n",
    "        float: likelihood of these two orders happening\n",
    "    \"\"\"\n",
    "    # translate first observation to state\n",
    "    state = np.zeros(2 * n + 1, dtype=int)\n",
    "    if len(order_1) > 0:\n",
    "        state[order_1] = 1\n",
    "    diag = get_diag_paired(log_theta=log_theta, n=n, state=state)\n",
    "\n",
    "    event_to_bin = {e: 1 << i for i, e in enumerate(np.sort(order_1))}\n",
    "\n",
    "    p = tau1 / (tau1 - diag[0])\n",
    "\n",
    "    st = np.zeros(2 * n + 1)\n",
    "    st_bin = 0  # binary state\n",
    "    seeded = False\n",
    "    for i, e in enumerate(order_1):\n",
    "        if not seeded:\n",
    "            if i % 2:  # if the seeding has not happened yet, every second event is just the second part of the joint development\n",
    "                continue\n",
    "            if e == 2 * n:  # seeding\n",
    "                seeded = True\n",
    "                st[-1] = 1\n",
    "                st_bin += event_to_bin[2 * n]\n",
    "                p *= (np.exp(log_theta[n, st[::2].astype(bool)\n",
    "                                       ].sum()) / (tau1 - diag[st_bin]))\n",
    "            else:\n",
    "                st[[e, e + 1]] = 1\n",
    "                st_bin += (event_to_bin[e] + event_to_bin[e + 1])\n",
    "                p *= (np.exp(log_theta[e // 2, st[::2].astype(bool)\n",
    "                                       ].sum()) / (tau1 - diag[st_bin]))\n",
    "        else:\n",
    "            st[e] = 1\n",
    "            st_bin += event_to_bin[e]\n",
    "            if not e % 2:  # PT event\n",
    "                p *= (np.exp(log_theta[e//2, st[::2].astype(bool)\n",
    "                                       ].sum()) / (tau1 - diag[st_bin]))\n",
    "            else:  # Met event\n",
    "                p *= (np.exp(log_theta[e//2, np.append(st[1::2].astype(bool), True)].sum()) / (\n",
    "                    tau1 - diag[st_bin]))\n",
    "        pass\n",
    "\n",
    "    st = np.append(state[1::2], [1])  # reduce to met events\n",
    "    k = len(order_2) + st.sum()\n",
    "    state = st.copy()\n",
    "    if len(order_2) > 0:\n",
    "        state[order_2 // 2] = 1\n",
    "    event_to_bin = {e: 1 << i for i, e in enumerate(np.nonzero(state)[0])}\n",
    "    st_bin = (st[state.astype(bool)] << np.arange(k)).sum()\n",
    "    diag = get_diag_unpaired(log_theta=log_theta, state=state)\n",
    "    p *= tau2 / (tau2 - diag[st_bin])\n",
    "\n",
    "    for i, e in enumerate(order_2):\n",
    "        e = e//2\n",
    "        st[e] = 1\n",
    "        st_bin += event_to_bin[e]\n",
    "        p *= (np.exp(log_theta[e, st.astype(bool)].sum()\n",
    "                     ) / (tau2 - diag[st_bin]))\n",
    "        pass\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "p1 = likelihood(order_1=np.array([0, 1, 16]), order_2=np.array(\n",
    "    [3]), log_theta=log_theta, tau1=tau1, tau2=tau2)\n",
    "p2 = likelihood(order_1=np.array([0, 1, 16, 3]), order_2=np.array(\n",
    "    []), log_theta=log_theta, tau1=tau1, tau2=tau2)\n",
    "print(p1, p2, p1+p2, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01111979588993203\n",
      "0.011221948441660332\n",
      "0.003331910222602588\n",
      "0.003920937334849716\n",
      "0.0021453627443374194\n",
      "0.006140151716180439\n",
      "0.005602120213425123\n",
      "0.002713252875738301\n",
      "0.04619547943872594\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for o1, o2 in [\n",
    "    ([0, 1, 4], []),\n",
    "    ([4], []),\n",
    "    ([4, 0, 1], []),\n",
    "    ([4, 0], []),\n",
    "    ([4, 0], [1]),\n",
    "    ([4], [1]),\n",
    "    ([4, 1], []),\n",
    "    ([4, 1, 0], []),\n",
    "]:\n",
    "    l = likelihood(np.array(o1), np.array(o2), log_theta, tau1, tau2)\n",
    "    print(l)\n",
    "    s += l\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def met(bin_state, pt):\n",
    "    return int(\"\".join(i for i, pt_ev in zip(bin(bin_state)[2:], pt[::-1]) if not pt_ev), base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 3, 2), 1.196753551784392e-07)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likeliest_order(state, log_theta, tau1, tau2):\n",
    "    k = state.sum()\n",
    "\n",
    "    n = log_theta.shape[0] - 1\n",
    "    pt = np.nonzero(state)[0] % 2 == 0 # whether active events belong to pt\n",
    "    pt[-1] = False\n",
    "    events = np.nonzero(state)[0] // 2 # event numbers\n",
    "    pt_events = np.nonzero(pt.astype(int))[0] # positions of the pt 1s\n",
    "    met_events = np.nonzero((~pt).astype(int))[0] # positions \n",
    "\n",
    "    diag_paired = get_diag_paired(log_theta=log_theta, n=n, state=state)\n",
    "    diag_unpaired = get_diag_unpaired(log_theta=log_theta, state=np.concatenate([state[1::2], state[-1::]]))\n",
    "\n",
    "    reachable = reachable_states(n)[ssr_to_fss(state)]\n",
    "\n",
    "    A1 = [dict(), {0: {tuple(): tau1 / (tau1 - diag_paired[0])}}]   # get there with tau1\n",
    "    A2 = [dict()]                                                   # get there with tau2\n",
    "    \n",
    "    for n_events in range(1, k + 1):\n",
    "        A1.append(dict())\n",
    "        A2.append(dict())\n",
    "        for current_state in bits_fixed_n(n=n_events, k=k):\n",
    "            if not reachable[current_state]:\n",
    "                continue\n",
    "            if current_state & (1 << (k - 1)):    # seeding has happened\n",
    "                state_events = [i for i in range(k) if (1 << i) | current_state == current_state] # positions of 1s\n",
    "                pt_terminal = np.isin(pt_events, state_events).all() # Does the pt part fit the observation?\n",
    "                A1[2][current_state] = dict()\n",
    "                denom1 = 1/(tau1 - diag_paired[current_state])\n",
    "\n",
    "                if pt_terminal:\n",
    "                    # if the pt part fits the observation, it is possible that the same holds for a prestate. Then we need\n",
    "                    # to calculate how we can reach current_state with tau2\n",
    "                    A2[1][current_state] = dict()\n",
    "\n",
    "                    denom2 = 1/(tau2 - diag_unpaired[met(current_state, pt)])\n",
    "                # fill A1[2][current_state] and A2[1][current_state] with probabilities to current_state \n",
    "\n",
    "                for pre_state, pre_orders1 in A1[1].items():\n",
    "                    \n",
    "                    # Skip pre_state if it is not a subset of current_state  \n",
    "                    if not (current_state | pre_state == current_state):\n",
    "                        continue\n",
    "\n",
    "                    # get the position of the new 1\n",
    "                    new_event = bin(current_state ^ pre_state)[:1:-1].index(\"1\") \n",
    "                    \n",
    "                    # Get the numerator\n",
    "                    if pt[new_event]:       # new event belongs to pt\n",
    "                        num = np.exp(log_theta[events[new_event], events[state_events][pt[state_events]]].sum())\n",
    "                    else:                   # new event belongs to met\n",
    "                        num = np.exp(log_theta[events[new_event], events[state_events][~pt[state_events]]].sum())\n",
    "\n",
    "                    # Assign the probabilities for A1\n",
    "                    for pre_order1, pre_prob1 in pre_orders1.items():\n",
    "                        A1[2][current_state][pre_order1 + (new_event,)] = num * pre_prob1 * denom1\n",
    "\n",
    "                    if pt_terminal:\n",
    "\n",
    "                        # Get the numerator\n",
    "                        num = np.exp(log_theta[events[new_event], events[state_events][~pt[state_events]]].sum())\n",
    "                        \n",
    "                        # if pre_state was pt_terminal\n",
    "                        if pre_state in A2[0]:\n",
    "                            for pre_order2, pre_prob2 in A2[0][pre_state].items():\n",
    "                                # get binary state w.r.t. met mhn of prestate\n",
    "                                A2[1][current_state][pre_order2 + (new_event,)] = \\\n",
    "                                    num * ((tau2 / (tau2 - diag_unpaired[met(pre_state, pt)]))* pre_orders1[pre_order2] + pre_prob2) * denom2\n",
    "                        else:\n",
    "                            for pre_order1 in A1[1][pre_state]:\n",
    "                                A2[1][current_state][pre_order1 + (new_event,)] = 0\n",
    "\n",
    "                # Now I have the two dicts A1[2][current_state] and A2[1][current_state] with possible paths to get \n",
    "                # to current_state. I can kick out some of them, because I am only interested in those orders that\n",
    "                # stand a chance to be maximal\n",
    "\n",
    "                if pt_terminal:\n",
    "                    A1[2][current_state], A2[1][current_state] = tuple_sort(A1[2][current_state], A2[1][current_state])\n",
    "\n",
    "            else: # seeding has not happened yet\n",
    "                state_events = [i for i in range(k) if (1 << i) | current_state == current_state] # positions of 1s\n",
    "\n",
    "                A1[2][current_state] = dict()\n",
    "\n",
    "                denom1 = 1/(tau1 - diag_paired[current_state])\n",
    "\n",
    "                for pre_state, pre_orders1 in A1[0].items():\n",
    "                    \n",
    "                    # Skip pre_state if it is not a subset of current_state  \n",
    "                    if not (current_state | pre_state == current_state):\n",
    "                        continue\n",
    "\n",
    "                    # get the position of the new 1\n",
    "                    new_event = bin(current_state ^ pre_state)[:1:-1].index(\"1\") \n",
    "                    \n",
    "                    num = np.exp(log_theta[events[new_event], events[state_events][pt[state_events]]].sum())\n",
    "\n",
    "                    # Assign the probabilities for A1\n",
    "                    for pre_order1, pre_prob1 in pre_orders1.items():\n",
    "                        A1[2][current_state][pre_order1 + (new_event, new_event + 1)] = num * pre_prob1 * denom1\n",
    "\n",
    "                likeliest = max(A1[2][current_state], key=A1[2][current_state].get)\n",
    "\n",
    "                A1[2][current_state] = {likeliest: A1[2][current_state][likeliest]}\n",
    "\n",
    "        pass\n",
    "\n",
    "        A1.pop(0)\n",
    "        A2.pop(0)\n",
    "\n",
    "    bin_state = int(\"1\" * k, base=2)\n",
    "\n",
    "    # if I came to the final state just with tau1, I still have to add the second observation, i.e.\n",
    "    # tau2/ (tau2 - q_finalstate)\n",
    "    final_factor = tau2 / (tau2 - diag_unpaired[-1]) \n",
    "    result = {k: v * final_factor + A2[0][bin_state][k] for k, v in A1[1][bin_state].items()}\n",
    "    return max(result, key=result.get), max(result.values())\n",
    "\n",
    "\n",
    "state = np.zeros(2 * n + 1, dtype=int)\n",
    "state[[0,1,3,-1]] = 1\n",
    "likeliest_order(state=state, log_theta=log_theta, tau1=tau1, tau2=tau2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import cm\n",
    "\n",
    "# f,a = plt.subplots(ncols=2, sharey=True)\n",
    "\n",
    "# for i in range(65,85):\n",
    "#     a[0].plot([0,1], [x[chr(i)], y[chr(i)]], label=chr(i), color=cm.hsv((i-65)/20))\n",
    "#     if chr(i) in x_hat.keys():\n",
    "#         a[1].plot([0,1], [x[chr(i)], y[chr(i)]], label=chr(i), color=cm.hsv((i-65)/20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
